# Exercice 2 : Pipeline ETL Temps R√©el avec Redpanda et PySpark

La vid√©o de d√©monstration est disponible ici : [Projet9_part2_video.mp4](https://youtu.be/wuiCFop4TZc)

## üìã Table des mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Pr√©requis](#pr√©requis)
- [Installation](#installation)
  - [Installation de Docker](#installation-de-docker)
  - [Configuration du projet](#configuration-du-projet)
- [D√©marrage rapide](#d√©marrage-rapide)
- [Utilisation](#utilisation)
- [Structure des donn√©es](#structure-des-donn√©es)
- [R√©sultats et sorties](#r√©sultats-et-sorties)
- [Troubleshooting](#troubleshooting)
- [Points cl√©s du projet](#points-cl√©s-du-projet)

---

## üéØ Vue d'ensemble

Ce projet impl√©mente un **pipeline ETL (Extract, Transform, Load) temps r√©el** pour la gestion de tickets clients. Il d√©montre comment :

- **Produire** des donn√©es en continu (tickets al√©atoires)
- **Streamer** les donn√©es via un broker Kafka (Redpanda)
- **Traiter** les donn√©es √† grande √©chelle avec Spark
- **Exporter** les r√©sultats en formats optimis√©s (Parquet/JSON)

**Use case :** Imaginz une entreprise recevant 1000+ tickets par jour. Ce syst√®me capture, enrichit et analyse les tickets automatiquement, 24/7.

---

## üèóÔ∏è Architecture

```mermaid
graph LR
    A["Producteur Python<br/>(Generator)"] -->|JSON| B["Redpanda<br/>(Kafka Broker)"]
    B -->|Messages| C["Processeur PySpark<br/>(ETL Engine)"]
    C -->|Transform| D["Enrichissement<br/>(Add Teams)"]
    D -->|Analyse| E["Exports<br/>(Parquet/JSON)"]
    
    style A fill:#e3f2fd
    style B fill:#fff3e0
    style C fill:#f3e5f5
    style D fill:#e8f5e9
    style E fill:#fce4ec
```

### Composants

| Composant | R√¥le | Technologies |
|-----------|------|--------------|
| **Producer** | G√©n√®re des tickets clients al√©atoires en continu | Python, Kafka-Python |
| **Redpanda** | Broker Kafka-compatible, persiste les messages | Redpanda (Docker) |
| **Processor** | Lit, transforme et enrichit les donn√©es | PySpark, Spark SQL |
| **Output** | Exporte les r√©sultats trait√©s | Parquet, JSON |

---

## üì¶ Pr√©requis

- **Syst√®me d'exploitation** : Linux Debian/Ubuntu (test√©) ou macOS/Windows avec WSL
- **RAM** : Minimum 4 GB (6+ GB recommand√©)
- **Espace disque** : 2 GB pour les conteneurs Docker
- **Port disponible** : 9092 (Redpanda)
- **Docker & Docker Compose** : Install√©s et en fonction

---

## üîß Installation

### Installation de Docker

#### Linux (Debian/Ubuntu)

```bash
# 1. Mettre √† jour les packages
sudo apt-get update
sudo apt-get upgrade -y

# 2. Installer Docker
sudo apt-get install -y docker.io docker-compose

# 3. Ajouter l'utilisateur courant au groupe docker (optionnel, pour √©viter sudo)
sudo usermod -aG docker $USER
newgrp docker

# 4. V√©rifier l'installation
docker --version
docker-compose --version
```

#### macOS

```bash
# Avec Homebrew (recommand√©)
brew install docker docker-compose

# Ou t√©l√©charger Docker Desktop depuis https://www.docker.com/products/docker-desktop
```

#### Windows

1. Installer **WSL2** (Windows Subsystem for Linux 2)
   ```powershell
   wsl --install
   ```

2. T√©l√©charger et installer **Docker Desktop for Windows**
   - https://www.docker.com/products/docker-desktop
   - Activer WSL2 dans les param√®tres Docker

3. V√©rifier l'installation
   ```powershell
   docker --version
   docker-compose --version
   ```

---

### Configuration du projet

#### 1. Cloner/Cr√©er le projet

```bash
# Cr√©er le r√©pertoire du projet
mkdir -p ~/projects
cd ~/projects

# Cloner le repository
git clone https://github.com/day811/OCDE-P9
cd OCDE-P9
```

#### 2. Structure du projet

Assurer que vous avez la structure suivante :

```
OCDE-P9/
‚îú‚îÄ‚îÄ README.md                    # Documentation (ce fichier)
‚îú‚îÄ‚îÄ docker-compose.yml           # Orchestration conteneurs
‚îú‚îÄ‚îÄ .env                         # Variables d'environnement
‚îú‚îÄ‚îÄ .gitignore                   # Exclusions Git
‚îú‚îÄ‚îÄ pyrightconfig.json           # Config type checking
‚îú‚îÄ‚îÄ producer/                    # Service producteur
‚îÇ   ‚îú‚îÄ‚îÄ ticket_producer.py      # Point d'entr√©e
‚îÇ   ‚îú‚îÄ‚îÄ producer.py             # Classe ProductionManager
‚îÇ   ‚îú‚îÄ‚îÄ ticket.py               # Mod√®le Ticket
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Image Docker
‚îú‚îÄ‚îÄ processor/                   # Service processeur
‚îÇ   ‚îú‚îÄ‚îÄ spark_processor.py      # Point d'entr√©e
‚îÇ   ‚îú‚îÄ‚îÄ processor.py            # Classe SparkProcessor
‚îÇ   ‚îú‚îÄ‚îÄ transformations.py      # Logique m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ config.py               # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile              # Image Docker
‚îú‚îÄ‚îÄ config/                      # Scripts utilitaires
‚îÇ   ‚îî‚îÄ‚îÄ redpanda_init.sh        # Initialisation Redpanda
‚îî‚îÄ‚îÄ data/                        # R√©pertoire donn√©es
    ‚îî‚îÄ‚îÄ output/                 # R√©sultats export
```

#### 3. Cr√©er les fichiers de configuration

Les fichiers sont fournis dans le `docker-compose.yml` et `.env`. Aucune configuration manuelle requise.

#### 4. V√©rifier les ports disponibles

```bash
# V√©rifier si le port 9092 est disponible
sudo lsof -i :9092  # Aucun r√©sultat = port libre
```

---

## üöÄ D√©marrage rapide

### √âtape 1 : Lancer l'ensemble du pipeline

```bash
cd ~/projects/OCDE-P9

# Construire et d√©marrer tous les conteneurs
docker-compose up --build

# Ou en mode d√©tach√© (arri√®re-plan)
docker-compose up -d --build
```

**Attendez que tous les services d√©marrent** (environ 30-45 sec) :

```
redpanda_exercice2 | Waiting for Redpanda to start...
init_redpanda      | Topic 'client_tickets' created successfully
ticket_producer    | Starting producer with config: ProducerConfig(...)
ticket_processor   | Starting processor with config: ProcessorConfig(...)
```

### √âtape 2 : V√©rifier le statut

```bash
# Voir l'√©tat des conteneurs
docker-compose ps

# Affichage attendu :
# NAME                     STATUS          PORTS
# redpanda_exercice2       Up 2 minutes    0.0.0.0:9092->9092/tcp
# init_redpanda            Exited          
# ticket_producer          Up 2 minutes    
# ticket_processor         Up 2 minutes
```

### √âtape 3 : Monitorer les logs

```bash
# Logs du producteur (tickets publi√©s)
docker-compose logs -f producer

# Logs du processeur (tickets trait√©s)
docker-compose logs -f processor

# Tous les logs en temps r√©el
docker-compose logs -f
```

### √âtape 4 : V√©rifier les r√©sultats

```bash
# Les fichiers appara√Ætront dans data/output/ apr√®s ~40 secondes
ls -la data/output/

# Exemple de sortie :
# total 128
# drwxr-xr-x 10 user group  4096 Dec 19 14:23 .
# drwxr-xr-x  3 user group  4096 Dec 19 14:20 ..
# drwxr-xr-x  2 user group  4096 Dec 19 14:23 tickets_with_assignment
# drwxr-xr-x  2 user group  4096 Dec 19 14:23 metrics
# drwxr-xr-x  2 user group  4096 Dec 19 14:23 tickets_by_type
# drwxr-xr-x  2 user group  4096 Dec 19 14:23 tickets_by_priority
# drwxr-xr-x  2 user group  4096 Dec 19 14:23 high_priority_tickets
```

### √âtape 5 : Arr√™ter le pipeline

```bash
# Arr√™ter tous les conteneurs (conserve les donn√©es)
docker-compose down

# Arr√™ter et supprimer tous les volumes (donn√©es perdues)
docker-compose down -v
```

---

## üíª Utilisation

### Configuration par variables d'environnement

√âditez `.env` pour personnaliser le comportement :

```bash
nano .env
```

**Param√®tres cl√©s :**

```env
# Redpanda / Kafka
REDPANDA_BROKER_LOCAL=redpanda:9092        # Adresse du broker
TOPIC_NAME=client_tickets                  # Nom du topic
TOPIC_PARTITIONS=3                         # Nombre de partitions
TOPIC_REPLICATION=1                        # Facteur de r√©plication

# Producteur
PRODUCER_RATE=10                           # Tickets par seconde
PRODUCER_TIMEOUT=30                        # Timeout de connexion (sec)

# Processeur Spark
SPARK_MEMORY=2g                            # M√©moire Spark
SPARK_EXECUTOR_CORES=2                     # Nombre de cores
OUTPUT_FORMAT=parquet                      # Format: parquet ou json
OUTPUT_PATH=/data/output                   # Chemin de sortie

# Logging
LOG_LEVEL=INFO                             # DEBUG, INFO, WARNING, ERROR
ENVIRONMENT=docker                         # docker ou local
```

**Red√©marrez apr√®s modification :**

```bash
docker-compose down
docker-compose up --build
```

### Surcharge par arguments CLI

**Producteur :**

```bash
docker-compose exec producer python ticket_producer.py --rate 20 --broker redpanda:9092
```

**Processeur :**

```bash
docker-compose exec processor python spark_processor.py --memory 4g --output-format json
```

---

## üìä Structure des donn√©es

### Format d'entr√©e (Ticket brut)

```json
{
  "ticket_id": "550e8400-e29b-41d4-a716-446655440000",
  "client_id": "CLIENT_5234",
  "created_at": "2025-12-19T14:23:45.123456Z",
  "request": "Unable to reset password",
  "request_type": "account",
  "priority": "high"
}
```

**Champs disponibles :**

| Champ | Type | Exemple | Validations |
|-------|------|---------|-------------|
| `ticket_id` | UUID | `550e8400-...` | Unique, requis |
| `client_id` | String | `CLIENT_1234` | Format `CLIENT_XXXX` |
| `created_at` | ISO8601 | `2025-12-19T14:23:45Z` | Timestamp UTC |
| `request` | String | `"Service not working"` | Max 500 chars |
| `request_type` | Enum | `billing`, `technical`, `account`, `general` | 4 valeurs |
| `priority` | Enum | `low`, `medium`, `high`, `critical` | 4 valeurs |

### Format de sortie (Ticket enrichi)

```json
{
  "ticket_id": "550e8400-e29b-41d4-a716-446655440000",
  "client_id": "CLIENT_5234",
  "created_at": "2025-12-19T14:23:45.123456Z",
  "request": "Unable to reset password",
  "request_type": "account",
  "priority": "high",
  "assigned_team": "Account Management"
}
```

**Champ ajout√© par enrichissement :**

| Champ | Source | Logique |
|-------|--------|--------|
| `assigned_team` | `request_type` | Mapping automatique pour routing |

---

## üì§ R√©sultats et sorties

### Emplacements des fichiers

Les r√©sultats sont export√©s dans `data/output/` avec la structure suivante :

```
data/output/
‚îú‚îÄ‚îÄ tickets_with_assignment/     # Tous les tickets enrichis
‚îÇ   ‚îî‚îÄ‚îÄ part-00000-c99...parquet
‚îú‚îÄ‚îÄ metrics/                      # Statistiques globales
‚îÇ   ‚îî‚îÄ‚îÄ part-00000-abc...parquet
‚îú‚îÄ‚îÄ tickets_by_type/              # Tickets group√©s par type
‚îÇ   ‚îî‚îÄ‚îÄ part-00000-def...parquet
‚îú‚îÄ‚îÄ tickets_by_priority/          # Tickets group√©s par priorit√©
‚îÇ   ‚îî‚îÄ‚îÄ part-00000-ghi...parquet
‚îî‚îÄ‚îÄ high_priority_tickets/        # Tickets critiques/hauts
    ‚îî‚îÄ‚îÄ part-00000-jkl...parquet
```

### Exemple de m√©triques globales

```json
{
  "total_tickets": 1523,
  "billing_count": 391,
  "technical_count": 456,
  "account_count": 402,
  "general_count": 274,
  "critical_priority_count": 87,
  "unique_clients": 312
}
```

### Consulter les r√©sultats

**Option 1 : Format JSON (lisible dans VSCode)**

```bash
# Modifier .env
OUTPUT_FORMAT=json

# Red√©marrer
docker-compose down -v && docker-compose up --build

# Ouvrir directement dans VSCode
code data/output/metrics/part-00000-*.json
```

**Option 2 : Format Parquet (optimis√©)**

```bash
# Avec Parquet Viewer (Extension VSCode)
# Clic droit ‚Üí Preview Parquet File

# Ou convertir en CSV
python -c "
import pandas as pd
df = pd.read_parquet('data/output/metrics')
print(df)
"
```

**Option 3 : Nettoyer la sortie Spark**

```bash
python view_results.py  # Script fourni pour simplifier la structure
```

---

## üêõ Troubleshooting

### Le port 9092 est d√©j√† utilis√©

```bash
# Identifier le processus
sudo lsof -i :9092

# Tuer le processus
sudo kill -9 <PID>

# Ou modifier le port dans docker-compose.yml et .env
```

### Les conteneurs ne d√©marrent pas

```bash
# Voir les erreurs
docker-compose logs redpanda

# Reconstruire from scratch
docker-compose down -v
docker system prune -a
docker-compose up --build
```

### Le processeur n'a pas de donn√©es

```bash
# V√©rifier que le producteur publie
docker-compose logs producer | tail -20

# V√©rifier le topic existe
docker exec redpanda_exercice2 rpk topic list

# Voir les messages dans le topic
docker exec redpanda_exercice2 rpk topic consume client_tickets
```

### Erreur : "Failed to find data source: kafka"

```bash
# Spark ne trouve pas le connecteur Kafka
# Solution : dans processor/processor.py, v√©rifier que init_spark() a :
#   .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0")
```

### Les fichiers Parquet ne se lisent pas directement

C'est normal ! Spark cr√©e une structure multi-fichiers :

```
metrics/
‚îú‚îÄ‚îÄ _SUCCESS           # Marqueur de succ√®s
‚îú‚îÄ‚îÄ ._SUCCESS.crc      # Checksum
‚îú‚îÄ‚îÄ .part-00000...     # Fichier temporaire
‚îî‚îÄ‚îÄ part-00000...      # ‚úÖ LE VRAI FICHIER
```

**Solution :** Utiliser le script `view_results.py` ou convertir en JSON.

### Performance lente

```bash
# Augmenter les ressources dans .env
SPARK_MEMORY=4g          # au lieu de 2g
SPARK_EXECUTOR_CORES=4   # au lieu de 2

# Ou r√©duire le timeout producteur
PRODUCER_TIMEOUT=15
```

---

## üéì Points cl√©s du projet

### 1. Producteur (Producer)

**R√¥le :** G√©n√©rer des tickets clients al√©atoires.

**Code cl√© :**

```python
# producer/ticket_producer.py
def generate_random_ticket() -> Ticket:
    """Cr√©e un ticket avec donn√©es al√©atoires."""
    return Ticket(
        ticket_id=str(uuid.uuid4()),
        client_id=f"CLIENT_{random.randint(1000, 9999)}",
        request=random.choice(SAMPLE_REQUESTS),
        request_type=random.choice(REQUEST_TYPES),
        priority=random.choice(PRIORITIES)
    )
```

**Concepts :**
- **Rate limiting :** Publi√© N tickets/sec pour simuler une charge r√©aliste
- **S√©rialisation JSON :** Conversion objet Python ‚Üí texte Kafka
- **Reconnexion automatique :** Gestion des d√©faillances r√©seau

### 2. Broker Redpanda (Kafka)

**R√¥le :** Persister les messages pour d√©couplage producteur/consommateur.

**Concepts :**
- **Topics :** Canaux logiques (`client_tickets`)
- **Partitions :** Parall√©lisme (3 partitions = 3 workers)
- **Offset :** Position de lecture, permet reprendre apr√®s crash
- **R√©plication :** Haute disponibilit√© (facteur = 1 en dev, 3+ en prod)

### 3. Processeur Spark

**R√¥le :** Transformer et enrichir les donn√©es √† l'√©chelle.

**Pipeline ETL :**

```python
# processor/transformations.py

# Extract
df = spark.read.kafka(...).select("ticket.*")

# Transform
df = Transformations.add_support_team(df)
metrics = Transformations.calculate_ticket_metrics(df)
by_priority = Transformations.group_by_priority(df)

# Load
df.write.parquet("data/output/tickets_with_assignment")
```

**Optimisations appliqu√©es :**
- **Coalesce(1) :** Merge partitions pour 1 fichier (plus simple √† lire)
- **Schema parsing :** Validation JSON avant traitement
- **Lazy evaluation :** Spark optimise la requ√™te avant ex√©cution

### 4. Architecture Batch vs Streaming

**Notre POC = BATCH (une seule ex√©cution)**

```
Start ‚Üí Read ALL data ‚Üí Process ‚Üí Export ‚Üí Exit
```

**Production = STREAMING (continu)**

```
Start ‚Üí Read MICRO-BATCH ‚Üí Process ‚Üí Export ‚Üí Repeat every 30sec ‚Üí ...
```

### 5. Concepts Data Engineering

| Concept | Application ici | Importance |
|---------|-----------------|-----------|
| **Sch√©ma validation** | Type checking JSON | Qualit√© donn√©es |
| **Partitioning** | 3 partitions Redpanda | Parall√©lisme |
| **Checkpointing** | `startingOffsets` | Reprendre apr√®s crash |
| **Idempotence** | M√™me ID = m√™me record | Pas de doublons |
| **Scalabilit√©** | Horizonal via partitions | Cro√Ætre sans limite |

---

## üìö Ressources compl√©mentaires

- **Apache Spark :** https://spark.apache.org/docs/latest/
- **Redpanda :** https://redpanda.com/documentation
- **Kafka Concepts :** https://kafka.apache.org/documentation/#concepts
- **Docker :** https://docs.docker.com/

---

## üìù Notes importantes

- **Donn√©es de test :** G√©n√©r√©es al√©atoirement, non persist√©es entre red√©marrages
- **Format Parquet :** Format columnar compress√©, optimal pour analyse
- **Checkpoint :** Spark peut reprendre depuis dernier offset en cas crash
- **Volume :** POC avec ~100-1000 tickets, production = millions/jour

---

## ü§ù Support et Questions

En cas de probl√®me :

1. Consulter la section [Troubleshooting](#troubleshooting)
2. V√©rifier les logs : `docker-compose logs <service>`
3. Valider la configuration `.env` et `docker-compose.yml`
4. S'assurer que Docker est op√©rationnel

---

**Derni√®re mise √† jour :** D√©cembre 2025  
**Version :** 1.0.0  
**Auteur :** OpenClassroom - Data Engineer Track
